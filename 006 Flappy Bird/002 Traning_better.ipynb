{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90225a07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65013,
     "status": "ok",
     "timestamp": 1753966551367,
     "user": {
      "displayName": "mustafa taha",
      "userId": "16679109722330067367"
     },
     "user_tz": -180
    },
    "id": "90225a07",
    "outputId": "3c27d8ac-aad5-4af2-f320-88dc333a686b"
   },
   "outputs": [],
   "source": [
    "# !pip install swing\n",
    "# !pip install gymnasium[box2d]\n",
    "# !pip install --upgrade moviepy\n",
    "# !pip install stable-baselines3\n",
    "# !sudo apt-get update\n",
    "# !sudo apt-get install -y swig\n",
    "# !sudo apt-get install -y python3-dev\n",
    "# !pip install \"gymnasium[box2d]\"\n",
    "# !pip install flappy-bird-gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "znmaR_AKh2PG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19091,
     "status": "ok",
     "timestamp": 1753966200449,
     "user": {
      "displayName": "mustafa taha",
      "userId": "16679109722330067367"
     },
     "user_tz": -180
    },
    "id": "znmaR_AKh2PG",
    "outputId": "9f3bb628-6931-4fe7-b495-8e7ef3cd7cd8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc3ab80",
   "metadata": {
    "id": "ebc3ab80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "# # %% Install required packages\n",
    "# !pip install flappy-bird-gymnasium stable-baselines3 moviepy gymnasium[box2d]\n",
    "\n",
    "# %% Imports\n",
    "import os\n",
    "import gymnasium\n",
    "import flappy_bird_gymnasium\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from moviepy import ImageSequenceClip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0638123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c82c99f126d40fc9da151f7275009a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">WARN: The obs returned by the `step()` method is not within the observation space.</span>\n",
       "  logger.warn(f\"{pre} is not within the observation space.\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \n",
       "\u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
       "  logger.warn(f\"{pre} is not within the observation space.\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2d3a6807eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Create directories\n",
    "log_dir = \"./ppo_logs/\"\n",
    "checkpoint_dir = \"./checkpoints/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# %% Create and wrap the environment\n",
    "env = gymnasium.make(\"FlappyBird-v0\", render_mode=\"rgb_array\", use_lidar=True)\n",
    "env = Monitor(env)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
    "\n",
    "# %% Define the PPO model\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    # verbose=1,\n",
    "    device=\"cuda\",  # ğŸ‘ˆ Forces use of GPU\n",
    "    tensorboard_log=log_dir,\n",
    "    n_steps=1024,\n",
    "    batch_size=64,\n",
    "    gae_lambda=0.95,\n",
    "    gamma=0.99,\n",
    "    n_epochs=10,\n",
    "    learning_rate=2.5e-4,\n",
    "    clip_range=0.2\n",
    ")\n",
    "\n",
    "# %% Add checkpoint callback\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=100_000,\n",
    "    save_path=checkpoint_dir,\n",
    "    name_prefix=\"ppo_flappy\"\n",
    ")\n",
    "\n",
    "# %% Train the model\n",
    "total_timesteps = 2_000_000\n",
    "model.learn(total_timesteps=total_timesteps, progress_bar=True, callback=checkpoint_callback)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90330912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Save model and VecNormalize stats\n",
    "model_name = f\"ppo_flappy_{total_timesteps}\"\n",
    "model.save(model_name)\n",
    "env.save(f\"{model_name}_vecnormalize.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "452aa688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation Result: Mean Reward = 15.70 Â± 31.00\n"
     ]
    }
   ],
   "source": [
    "# %% Evaluate the model\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"âœ… Evaluation Result: Mean Reward = {mean_reward:.2f} Â± {std_reward:.2f}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c746d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"FlappyBird-v0\", render_mode=\"rgb_array\", use_lidar=True)\n",
    "env = Monitor(env)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e874f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Recording 5 episodes of the trained agent...\n",
      "MoviePy - Building video videos/ppo_flappy_2000000_episode_1.mp4.\n",
      "MoviePy - Writing video videos/ppo_flappy_2000000_episode_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready videos/ppo_flappy_2000000_episode_1.mp4\n",
      "âœ… Saved video for Episode 1 - Reward: 11.18974781036377, Steps: 631\n",
      "MoviePy - Building video videos/ppo_flappy_2000000_episode_2.mp4.\n",
      "MoviePy - Writing video videos/ppo_flappy_2000000_episode_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready videos/ppo_flappy_2000000_episode_2.mp4\n",
      "âœ… Saved video for Episode 2 - Reward: -2.7562689781188965, Steps: 50\n",
      "MoviePy - Building video videos/ppo_flappy_2000000_episode_3.mp4.\n",
      "MoviePy - Writing video videos/ppo_flappy_2000000_episode_3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready videos/ppo_flappy_2000000_episode_3.mp4\n",
      "âœ… Saved video for Episode 3 - Reward: -0.27411776781082153, Steps: 50\n",
      "MoviePy - Building video videos/ppo_flappy_2000000_episode_4.mp4.\n",
      "MoviePy - Writing video videos/ppo_flappy_2000000_episode_4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready videos/ppo_flappy_2000000_episode_4.mp4\n",
      "âœ… Saved video for Episode 4 - Reward: -2.387612819671631, Steps: 50\n",
      "MoviePy - Building video videos/ppo_flappy_2000000_episode_5.mp4.\n",
      "MoviePy - Writing video videos/ppo_flappy_2000000_episode_5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready videos/ppo_flappy_2000000_episode_5.mp4\n",
      "âœ… Saved video for Episode 5 - Reward: 33.7279052734375, Steps: 1457\n",
      "\n",
      "ğŸ“Š Summary of Evaluation Episodes:\n",
      "Episode 1: Reward = 11.19, Steps = 631\n",
      "Episode 2: Reward = -2.76, Steps = 50\n",
      "Episode 3: Reward = -0.27, Steps = 50\n",
      "Episode 4: Reward = -2.39, Steps = 50\n",
      "Episode 5: Reward = 33.73, Steps = 1457\n",
      "\n",
      "âœ… Average Reward: 7.90 Â± 13.89\n",
      "âœ… Average Steps: 447.60 Â± 552.59\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from moviepy import ImageSequenceClip\n",
    "import os\n",
    "\n",
    "print(\"ğŸ¥ Recording 5 episodes of the trained agent...\")\n",
    "\n",
    "reward_queue = []\n",
    "time_queue = []\n",
    "video_output_dir = \"videos\"\n",
    "os.makedirs(video_output_dir, exist_ok=True)\n",
    "\n",
    "n_episodes = 5\n",
    "\n",
    "for episode in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = [False]\n",
    "    frames = []\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "\n",
    "    while not done[0]:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward[0]\n",
    "        steps += 1\n",
    "\n",
    "        frame = env.envs[0].render()\n",
    "        if isinstance(frame, np.ndarray) and frame.shape[-1] == 3:\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Episode {episode}: Skipping a malformed frame at step {steps}.\")\n",
    "\n",
    "    # Track stats\n",
    "    reward_queue.append(total_reward)\n",
    "    time_queue.append(steps)\n",
    "\n",
    "    # Save video\n",
    "    if frames:\n",
    "        clip = ImageSequenceClip(frames, fps=30)\n",
    "        video_path = f\"{video_output_dir}/{model_name}_episode_{episode}.mp4\"\n",
    "        clip.write_videofile(video_path, fps=30)\n",
    "        print(f\"âœ… Saved video for Episode {episode} - Reward: {total_reward}, Steps: {steps}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Episode {episode}: No valid frames captured.\")\n",
    "\n",
    "# After all episodes\n",
    "print(\"\\nğŸ“Š Summary of Evaluation Episodes:\")\n",
    "for i, (r, t) in enumerate(zip(reward_queue, time_queue), start=1):\n",
    "    print(f\"Episode {i}: Reward = {r:.2f}, Steps = {t}\")\n",
    "\n",
    "print(f\"\\nâœ… Average Reward: {np.mean(reward_queue):.2f} Â± {np.std(reward_queue):.2f}\")\n",
    "print(f\"âœ… Average Steps: {np.mean(time_queue):.2f} Â± {np.std(time_queue):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f84df6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06786b44641f49b0beb8a2add74a4e49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b6ff547e24f4e4895e4da2ba44efcef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4659946fd4d34ed5876efb7869ecb167": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_06786b44641f49b0beb8a2add74a4e49",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">   0%</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">411/500,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:04</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">1:32:11</span> , <span style=\"color: #800000; text-decoration-color: #800000\">90 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m   0%\u001b[0m \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m411/500,000 \u001b[0m [ \u001b[33m0:00:04\u001b[0m < \u001b[36m1:32:11\u001b[0m , \u001b[31m90 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "ec802382a0fa4ef89e426029365a9186": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_2b6ff547e24f4e4895e4da2ba44efcef",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">501,751/500,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:55:25</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">70 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m501,751/500,000 \u001b[0m [ \u001b[33m1:55:25\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m70 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
