{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c09b661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "from gymnasium.wrappers import TransformObservation\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "# ===============================================\n",
    "# Environment Setup\n",
    "# ===============================================\n",
    "\n",
    "# Grayscale + Resize function to preprocess the observation\n",
    "def preprocess_obs(obs):\n",
    "    \"\"\"\n",
    "    Converts a raw RGB observation from the environment to a single-channel,\n",
    "    resized grayscale image.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    return np.expand_dims(resized, axis=-1).astype(np.uint8)\n",
    "\n",
    "# Define the new observation space\n",
    "new_obs_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "# Factory function to create the wrapped environment\n",
    "def make_env():\n",
    "    \"\"\"\n",
    "    Creates and returns a single instance of the CarRacing-v3 environment\n",
    "    with the necessary wrappers for preprocessing and monitoring.\n",
    "    \"\"\"\n",
    "    env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\", continuous=True)\n",
    "    env = TransformObservation(env, func=preprocess_obs, observation_space=new_obs_space)\n",
    "    env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "# Create a vectorized environment from the factory function\n",
    "env = DummyVecEnv([make_env])\n",
    "\n",
    "# Stack 4 frames together to capture motion over time\n",
    "env = VecFrameStack(env, n_stack=4, channels_order=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f06240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3 import PPO\n",
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize PPO hyperparameters.\n",
    "    \"\"\"\n",
    "    # Define the search space for PPO hyperparameters\n",
    "    # You can choose which hyperparameters you want to tune\n",
    "    # and what their search ranges should be.\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    n_steps = trial.suggest_int('n_steps', 2048, 8192, log=True)\n",
    "    gamma = trial.suggest_uniform('gamma', 0.9, 0.999)\n",
    "    ent_coef = trial.suggest_uniform('ent_coef', 0.0, 0.1)\n",
    "    clip_range = trial.suggest_uniform('clip_range', 0.1, 0.4)\n",
    "    batch_size = trial.suggest_int('batch_size', 64, 512, log=True)\n",
    "    n_epochs = trial.suggest_int('n_epochs', 5, 20)\n",
    "\n",
    "    # Note: For CarRacing, a CNN policy is used. You can also tune network architecture,\n",
    "    # but let's start with the standard PPO hyperparameters first.\n",
    "    \n",
    "    # Create the PPO model with the suggested hyperparameters\n",
    "    # Ensure you are using the correct policy (CnnPolicy) for the CarRacing environment\n",
    "    model = PPO(\"CnnPolicy\", \n",
    "                env, \n",
    "                learning_rate=learning_rate,\n",
    "                n_steps=n_steps,\n",
    "                gamma=gamma,\n",
    "                ent_coef=ent_coef,\n",
    "                clip_range=clip_range,\n",
    "                batch_size=batch_size,\n",
    "                n_epochs=n_epochs,\n",
    "                verbose=0) # Set verbose to 0 to avoid printing too much info\n",
    "\n",
    "    # Set up evaluation and pruning\n",
    "    # It's crucial to evaluate the model periodically and report the score to Optuna.\n",
    "    # Optuna can then use a pruner to stop unpromising trials early.\n",
    "    eval_env = DummyVecEnv([make_env])\n",
    "    eval_env = VecFrameStack(eval_env, n_stack=4, channels_order=\"last\")\n",
    "    \n",
    "    # A custom callback is often used for this. Stable-Baselines3 provides an EvalCallback.\n",
    "    # We will use this to evaluate the policy and report to Optuna.\n",
    "    # You can also use a custom callback that integrates with Optuna's pruning.\n",
    "    \n",
    "    # A simple approach is to use evaluate_policy at the end of the training\n",
    "    try:\n",
    "        model.learn(total_timesteps=20_000, progress_bar=True) # Train for a set number of timesteps per trial\n",
    "        mean_reward, _ = evaluate_policy(model, eval_env, n_eval_episodes=5, deterministic=True)\n",
    "    finally:\n",
    "        eval_env.close()\n",
    "\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3640c92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 13:32:01,967] A new study created in memory with name: no-name-7afb64d3-8264-412d-8ad4-1956afc44e5d\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13064\\2287850575.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13064\\2287850575.py:14: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  gamma = trial.suggest_uniform('gamma', 0.9, 0.999)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13064\\2287850575.py:15: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  ent_coef = trial.suggest_uniform('ent_coef', 0.0, 0.1)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13064\\2287850575.py:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  clip_range = trial.suggest_uniform('clip_range', 0.1, 0.4)\n",
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning: You have specified a mini-batch size of 91, but because the `RolloutBuffer` is of size `n_steps * n_envs = 7186`, after every 78 untruncated mini-batches, there will be a truncated mini-batch of size 88\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=7186 and n_envs=1)\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning: You have specified a mini-batch size of 155, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2806`, after every 18 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=2806 and n_envs=1)\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning: You have specified a mini-batch size of 242, but because the `RolloutBuffer` is of size `n_steps * n_envs = 3356`, after every 13 untruncated mini-batches, there will be a truncated mini-batch of size 210\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=3356 and n_envs=1)\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning: You have specified a mini-batch size of 91, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2292`, after every 25 untruncated mini-batches, there will be a truncated mini-batch of size 17\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=2292 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create the Optuna study with pruning enabled\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=1)\n",
    ")\n",
    "\n",
    "# Optimize the objective\n",
    "study.optimize(objective, n_trials=50, n_jobs=-1)\n",
    "\n",
    "# %%\n",
    "# Print best result\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "print(f\"Best mean reward: {study.best_value}\")\n",
    "\n",
    "# Visualize the results\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Optuna study. We want to maximize the mean reward.\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "\n",
    "# Run the optimization\n",
    "# n_trials is the number of hyperparameter combinations to try.\n",
    "# You can increase this for a more thorough search.\n",
    "study.optimize(objective, n_trials=50, n_jobs=-1) # n_jobs=-1 to use all cores\n",
    "\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "print(f\"Best mean reward: {study.best_value}\")\n",
    "\n",
    "# Visualize the results\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebff82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
